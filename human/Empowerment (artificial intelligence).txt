Empowerment in the field of artificial intelligence  formalises and quantifies (via information theory) the potential an agent perceives that it has to influence its environment. An agent which follows an empowerment maximising policy, acts to maximise future options (typically up to some limited horizon). Empowerment can be used as a (pseudo) utility function that depends only on information gathered from the local environment to guide action, rather than seeking an externally imposed goal, thus is a form of intrinsic motivation. 
The empowerment formalism depends on a probabilistic model commonly used in artificial intelligence. An autonomous agent operates in the world by taking in sensory information and acting to change its state, or that of the environment, in a cycle of perceiving and acting known as the perception-action loop. Agent state and actions are modelled by random variables (
  
    
      
        S
        :
        s
        ∈
        
          
            S
          
        
        ,
        A
        :
        a
        ∈
        
          
            A
          
        
      
    
    {\displaystyle S:s\in {\mathcal {S}},A:a\in {\mathcal {A}}}
  
) and time (
  
    
      
        t
      
    
    {\displaystyle t}
  
). The choice of action depends on the current state, and the future state depends on the choice of action, thus the perception-action loop unrolled in time forms a causal bayesian network.